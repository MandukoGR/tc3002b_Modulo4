# Clasificaci√≥n de im√°genes de expresiones faciales con CNN
# Conjunto de datos inicial
El conjunto de datos utilizado para este proyecto se obtuvo de [Kaggle](https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer)

Este conjunto de datos contiene 35,887 im√°genes en escala de grises de rostros humanos con diferentes expresiones faciales. Las im√°genes tienen un tama√±o de 48x48 p√≠xeles. 


Este conjunto de datos ya se encuentra dividido en dos subconjuntos: train y test, con una proporci√≥n de 80% para entrenamiento y 20% para evaluaci√≥n. Cada subconjunto se compone de siete carpetas, cada una de las cuales representa una clase de expresi√≥n facial:


| Clase          | Test (cantidad de im√°genes) | Train (cantidad de im√°genes) |
| -------------- | --------------------------- | ---------------------------- |
| angry          | 958                         | 3995                         |
| disgusted      | 111                         | 436                          |
| fearful        | 1024                        | 4097                         |
| happy          | 1774                        | 7215                         |
| neutral        | 1233                        | 4965                         |
| sad            | 1247                        | 4830                         |
| surprised      | 831                         | 3171                         |


# Divisi√≥n de conjunto de datos
Se decidi√≥ modificar la estructura del conjunto de datos. Esto para generar un mejor balance de datos y tambi√©n incluir un subconjunto de datos destinado a validaci√≥n.

En primer lugar, se redujo el n√∫mero de clases de 7 a 5 eliminando las clases de "disgusted" y "surprised" debido a su poca cantidad de datos en comparaci√≥n con las otras clases.

Posteriormente, el conjunto de datos fue dividido en tres subconjuntos:
- **Train**: Es el subconjunto de datos que se utilizar√° para entrenar al modelo
- **Test**: Los datos en este subconjunto se utilizar√°n para evaluar el rendimiento del modelo con im√°genes nuevas que no han sido utilizadas para el entrenamiento del modelo.
- **Validation**: Los datos en este subconjunto ser√°n utilizados para evaluar el rendimiento del modelo durante el entrenamiento y poder ajustar los hiperpar√°metros del modelo antes de evaluar el modelo con el conjunto de prueba.

Se realiz√≥ una divisi√≥n del 70%, 15% y 15% de la totalidad de los datos, siendo el primer conjunto para entrenamiento, el segundo para validaci√≥n y el tercero para pruebas. Para esto, se renombraron las imagenes de train y test de cada clase utiizando el programa "rename.py", debido a que contaban con el mismo nombre y no era posible combinar las carpetas. Despu√©s de renombrar las im√°genes se combinaron las carpetas train y test y se utiliz√≥ el programa "split_data.py" obtenido de [Kaggle](https://www.kaggle.com/code/shuvostp/split-folders-for-train-test-val-split-of-images) para hacer la divisi√≥n deseada.

Por lo tanto, la estructura final del conjunto de datos cuenta con un total de 31,339 im√°genes, donde estas se distribuyen de la siguiente manera:

| Clase          | Test (cantidad de im√°genes) | Train (cantidad de im√°genes) | Validation (cantidad de im√°genes) |
| -------------- | --------------------------- | ---------------------------- | --------------------------------- |
| angry          | 744                         | 3467                         | 742
| fearful        | 769                         | 3584                         | 768
| happy          | 1349                        | 6292                         | 1349
| neutral        | 931                         | 4338                         | 929
| sad            | 913                         | 4253                         | 911

Es importante mencionar que la correcta divisi√≥n de los datos evita tener problemas como sobreentrenamiento o subentrenamiento. El sobreentrenamiento u **overfitting** ocurre cuando el modelo se ajusta perfectamente o casi perfectamente a los datos de entrenamiento pero tiene un mal rendimiento con datos nuevos. Esto puede ocurrir si se utiliza la totalidad de un conjunto de datos para entrenar un modelo. Por otro lado, el subentrenamiento o **underfitting** sucede cuando la arquitectura del modelo no es lo suficientemente compleja o cuando los datos de entrenamiento no son suficientes.


# Preprocesado de datos y t√©cnicas de escalamiento

Para realizar el preprocesado de las im√°genes, en este proyecto se utiliza el generador de datos **ImageDataGenerator** de Tensorflow. Este cuenta con par√°metros configurables que permiten indicar al generador las modificaciones que se realizar√°n en las im√°genes. En este caso, se modificaran los siguientes par√°metros:

- **Rotaci√≥n**: La im√°genes pueden ser rotadas hasta 180 grados, ya que esto no altera las caracter√≠sticas de una expresi√≥n facial.
- **Brillo**: Se puede ajustar el brillo de las imagenes mientras la imagen siga siendo visible, esto puede realizarse utilizando un rango entre 0.1 y 0.9 en la propiedad brightness_range de ImageDataGenerator.
- **Reescalamiento**: Escalamiento de los valores de los p√≠xeles de las im√°genes dividiendo el valor de cada p√≠xel entre 255.
- **Zoom**: Se utilizar√°n valores entre menores a 1 para solamente generar acercamientos. Es importante que el acercamiento no sea demasiado porque se pueden perder partes importantes de la imagen.
- **Flip horizontal**: El flip horizontal refleja la imagen de forma horizontal. En este conjunto de datos se puede utilizar debido a que no altera las expresiones faciales.

Otros par√°metros de ImageDataGenerator como shear o width shifting no fueron utilizados debido a que pueden alterar la expresi√≥n del un rostro.

Finalmente los par√°metros utilizados fueron:
```python
train_datagen = ImageDataGenerator(
                                    rescale = 1./255, # Reescalamiento
                                    rotation_range = 180, # Rotaci√≥n de 180 grados
                                    brightness_range= (0.1, 0.9), # Nivel de brillo
                                    zoom_range = 0.2, # Zoom
                                    horizontal_flip = True,) # Reflejo horizontal
```
Se realiz√≥ el c√≥digo "preprocess.py" para probar el ImageDataGenerator configurado. Se utiliz√≥ un batch de 10 para que se generen 10 im√°genes que son almacenadas en la carpeta augmented que se encuentra dentro de data.


# Modelo


La arquitectura del modelo es la propuesta por Bodapati y Strilakshmi en el art√≠culo de investigaci√≥n "A Deep CNN Architecture for Facial Expression Recognition in the Wild.". La cual obtuvo un 69% de test accuracy sin utilizar registro de puntos de referencia faciales antes de realizar la clasificaci√≥n. Adem√°s la arquitectura es simple comparada con arquitecturas como la propuesta por Amil Khanzada, Charles Bai y Ferhat Turker Celepcikay en el art√≠culo "Facial Expression Recognition with Deep Learning" que alcanza hasta un 73.2% de test accuracy utilizando transfer learning pero con un tiempo de entrenamiento de por lo menos 20 horas (con el equipo de c√≥mputo que tengo disponible).
La arquitectura consiste de 5 bloques convulucionales, donde cada bloque cuenta con dos capas convulucionales con filtros de 4x4 inicializadas con "Xavier weight initialization" , una capa de normalizaci√≥n de batches, un maxpooling de 2x2 y un dropout de 0.5. Finalmente se incluye una capa de aplanamiento y una capa densa con un tama√±o de 5 neuronas (en la arquitectura original son 7 pero debido a la reducci√≥n de clases que se realiz√≥ ahora es 5). En la siguiente imagen se ilustra la arquitectura elegida. 

![Arquitectura](/images/architecture.png)

Los conceptos clave de esta arquitectura son los siguientes:
1. **5 Bloques Convolucionales**: El modelo est√° compuesto por cinco bloques, donde cada bloque realiza ciertas operaciones espec√≠ficas.
2. **Capas Convolucionales (Convolutional Layers)**: Cada bloque contiene dos capas convolucionales que se encargan de aplicar filtros para extraer caracter√≠sticas de la imagen.
3. **Filtros Convolucionales**: Son matrices de 4x4 que se usan para convolver la imagen y detectar patrones locales como bordes, texturas, etc.
4. **Inicializaci√≥n con "Xavier Weight Initialization"**: M√©todo de inicializaci√≥n de los pesos de los filtros, dise√±ado para mantener la varianza de los activaciones a trav√©s de las capas, promoviendo una convergencia m√°s r√°pida y estable durante el entrenamiento.
5. **Capa de Normalizaci√≥n de Batches (Batch Normalization Layer)**: Normaliza las activaciones de la capa anterior, estabilizando y acelerando el proceso de entrenamiento al mantener la media y la varianza constantes.
6. **Dropout de 0.5**: T√©cnica de regularizaci√≥n que desactiva aleatoriamente el 50% (0.5) de las neuronas durante el entrenamiento, ayudando a prevenir el sobreajuste (overfitting).
7. **Capa de Aplanamiento (Flatten Layer)**: Transforma las matrices multidimensionales de las capas convolucionales en un vector unidimensional, prepar√°ndolo para la capa densa.
8. **Capa Densa**: La capa final del modelo tiene cinco neuronas, que corresponden a las cinco clases de expresiones faciales a reconocer. Originalmente eran siete neuronas (para siete clases) pero se redujeron a cinco debido a una reducci√≥n en el n√∫mero de clases.

Para compilar y entrenar el modelo se utilizaron 50 epochs con un tama√±o de batch de 64. Los hiperpar√°metros utilizados, tambi√©n obtenidos del art√≠culo de investigaci√≥n, son los siguientes:

| Hiperpar√°metro | Valor                      |
| -------------- | -------------------------- |
| Loss           | Categorical Crossentropy   |
| Optimizer      | Adam                       | 
| Learning rate  | 0.001                      |
| Weight decay   | 0.000001                   |
| momentum       | 0.9                        |

### Loss (Funci√≥n de P√©rdida):
- Categorical Crossentropy: Es una funci√≥n de p√©rdida utilizada para problemas de clasificaci√≥n multiclase. Mide la diferencia entre la distribuci√≥n de probabilidad predicha y la distribuci√≥n real de las clases.
### Optimizer (Optimizador):
- Adam: Es un algoritmo de optimizaci√≥n adaptativa que ajusta los par√°metros del modelo bas√°ndose en estimaciones de momentos de primer y segundo orden (medias y varianzas de los gradientes). Es conocido por su eficiencia y efectividad en el entrenamiento de redes neuronales.
### Learning Rate (Tasa de Aprendizaje):
- 0.001: La tasa de aprendizaje es un hiperpar√°metro que controla el tama√±o de los pasos que da el optimizador al actualizar los par√°metros del modelo. Un valor de 0.001 indica que los ajustes a los pesos del modelo ser√°n peque√±os en cada actualizaci√≥n, permitiendo un aprendizaje m√°s suave y estable.
### Weight Decay (Decaimiento de los Pesos):
- 0.000001: El weight decay es una t√©cnica de regularizaci√≥n que a√±ade un t√©rmino de penalizaci√≥n a la funci√≥n de p√©rdida proporcional a la magnitud de los pesos. Esto ayuda a prevenir el sobreajuste al restringir el crecimiento excesivo de los pesos.
### Momentum (Momento):
- 0.9: El momentum es una t√©cnica utilizada en optimizaci√≥n para acelerar el entrenamiento de redes neuronales. Ayuda a suavizar las actualizaciones de los par√°metros acumulando una fracci√≥n de las actualizaciones pasadas (0.9 en este caso) y us√°ndolas para actualizar los par√°metros actuales. Esto ayuda a evitar oscilaciones y a mantener el modelo en la direcci√≥n correcta hacia el m√≠nimo de la funci√≥n de p√©rdida.



# Diagn√≥stico de resultados iniciales

## Resultados
|                 | Train           | Validation       | Test          |
| --------------  | --------------- | ---------------- | ------------- |
| accuracy        | 0.6782          | 0.6592           | 0.6658        |
| loss            | 0.8462          | 0.9161           | 0.8900        |

Con respecto a los resultados obtenidos en el art√≠culo de referencia, los resultados obtenidos son buenos. Ya que se acercan al 69% de accuracy obtenido en el estado del arte. Sin embargo, los resultados siguen teniendo un porcentaje de accuracy peque√±o y difieren en un 3% con los del estado del arte. A√∫n as√≠ se puede notar en la siguiente imagen que el accuracy y el loss tanto en train como validation tuvo un buen comportamiento durante los epochs.
![Acc_Loss](/images/acc_loss_grafs.png)

Se gener√≥ una matriz de confusi√≥n para obtener la cantidad de predicciones verdaderas, falsos positivos y falsos negativos de cada clase. La matriz es la siguiente:
![M√°triz](/images/matrixog.png)

De acuerdo con la matriz, la clase que tuvo un mejor n√∫mero de predicciones correctas fue la clase "happy", seguido de la clase "neutral", la clase "angry", la clase "sad" y la clase "fearful". Por otro lado, se nota que todas las clases (exceptuando la clase "happy"), tienen un alto n√∫mero de predicciones incorrectas. Por ejemplo, las clases "sad" y "angry" se confunden con la clase "neutral" y la clase "fearful" se confunde con "angry", "neutral" y "sad".

Utilizando esta matriz se obtuvieron las siguientes m√©tricas:

### Precisi√≥n (Precision):
- La precisi√≥n es la proporci√≥n de verdaderos positivos (ùëáùëÉ) entre todos los ejemplos que el modelo ha etiquetado como positivos. En otras palabras, mide la exactitud de las predicciones positivas del modelo. Una alta precisi√≥n indica que el modelo comete pocos errores al etiquetar ejemplos como positivos (es decir, pocos falsos positivos).

### Recall (Sensibilidad o Tasa de Verdaderos Positivos):
- El recall es la proporci√≥n de verdaderos positivos entre todos los ejemplos que son realmente positivos. Mide la capacidad del modelo para identificar todos los ejemplos positivos. Un alto recall indica que el modelo es capaz de encontrar la mayor√≠a de los ejemplos positivos (es decir, pocos falsos negativos).

### F1-Score
El F1-score es la media arm√≥nica de la precisi√≥n y el recall. Es una m√©trica combinada que equilibra ambos aspectos, proporcionando una √∫nica medida del rendimiento del modelo cuando se consideran igualmente importantes tanto la precisi√≥n como el recall. Un alto F1-score indica que el modelo tiene un buen equilibrio entre precisi√≥n y recall. Es especialmente √∫til cuando se necesita una medida √∫nica del rendimiento del modelo en problemas de clasificaci√≥n con una distribuci√≥n de clases desequilibrada.

En cuanto a los resultados de precision, recall y f1-score, se obtuvo lo siguiente:
![Reporte](/images/classification_report.png)

Se puede notar que la clase "happy" tiene un puntaje mucho mayor que las otras clases en todas las m√©tricas. Esto puede ser debido a que se cuentan con m√°s datos en la clase "happy". Por otro lado, la clase "sad" cuenta con un puntaje bajo donde tanto la precision, el recall y el f1-score son de entre 0.53 y 0.54, lo que representa una diferencia de aproximadamente 0.3 con la clase "happy".

Debido a los resultados bajos en accuracy y en las m√©tricas de recall, precision y f1-score, se puede concluir que falta entrenar al modelo o que el modelo tiene **underfitting**. Esto debido a que hay un gran n√∫mero de predicciones para cada clase que no fueron las correctas. Esto se puede deber a una o varias de las siguientes opciones:

1. Desbalance de Clases:
La clase happy tiene un mayor n√∫mero de im√°genes que las otras clases (con una diferencia entre 2000 y 3000 aproximadamente), es decir, el modelo tiene muchas m√°s muestras de una clase que de las otras, por lo que el modelo podr√≠a estar aprendiendo a predecir siempre la clase mayoritaria. Esto puede resultar en una alta cantidad de verdaderos positivos (TP) pero tambi√©n en una alta cantidad de falsos positivos (FP) y falsos negativos (FN), lo cual afectar√° negativamente las m√©tricas de precisi√≥n, recall y F1 score.

2. Errores en el Preprocesamiento de Datos:
Los datos deben estar correctamente preprocesados para asegurar que el modelo pueda aprender de ellos de manera efectiva. Agregar par√°metros en el ImagedataGenerator podr√≠a ayudar a generalizar m√°s los datos y que el modelo tenga un mejor comportamiento con datos que nunca ha utilizado.

# Mejora del modelo
Para mejorar el modelo se realiz√≥ lo siguiente:
### Modificaci√≥n de dropout
Se decidi√≥ modificar el dropout de 0.5 a 0.4 para desactivar de forma aleatoria solamente el 40% de las neuronas. Este decremento de solo 10% fue para que el riesgo de sobreajuste no aumentar√° considerablemente y se mejorara la capacidad del modelo para generalizar a nuevos datos.
### Modificaci√≥n de learning rate
Aunque se mantuvo el learning rate inicial de 0.001, se utiliz√≥ el callback ReduceLROnPlateau, el cual monitore√≥ el valor de accuracy en validation set. En caso de que el validation accuracy no mejorar√° en 6 epochs consecutivas, se multiplicaba el learning rate actual por un factor de 0.1. En este caso, en el epoch 59 el learning rate se redujo a 0.0001 y en el epoch 86 se redujo a 0.0001.
### Modificaci√≥n de epochs
Se aument√≥ el n√∫mero de epochs de 50 a 100 y se utiliz√≥ el callback EarlyStopping. Si el validation accuracy no mejoraba en 10 epochs consecutivas se deten√≠a el entrenamiento. En este caso, esto sucedi√≥ en el epoch 90.
### Checkpoint
Se utiliz√≥ un checkpoint para guardar el modelo con mejor validation accuracy.
### Modificaci√≥n de ImageDataGenerator
Se agregaron los par√°metros de widht shift y height shift al train generator y se aument√≥ el batch de 64 a 128, esto para que el modelo tuviera una mejor generalizaci√≥n de datos y se comportara mejor con datos que no conoce.
### Combinaci√≥n de dataset
Se descubri√≥ que el dataset elegido tiene una gran cantidad de im√°genes que est√°n mal clasificadas lo que genera un alto nivel de ruido. Por lo tanto, se decidi√≥ combinar el data set CK+ obtenido de [Kaggle](https://www.kaggle.com/datasets/shuvoalok/ck-dataset), que a pesar de ser peque√±o no cuenta con ruido. Esto se realiz√≥ con la intenci√≥n de que el modelo tuviera una mayor cantidad de datos etiquetados correctamente. Se agregaron 391 im√°genes en train, 94 en test y 88 en validation.

Los resultados de accuracy y loss en validation, train y test fueron los siguientes:

|                 | Train           | Validation       | Test          |
| --------------  | --------------- | ---------------- | ------------- |
| accuracy        | 0.7213          | 0.6822           | 0.6817        |
| loss            | 0.7161          | 0.8804           | 0.8728        |

Comparado con el modelo original, test y validation tuvieron aproximadamente 2% mejor accuracy y loss. 

De igual manera, la matriz de confusi√≥n arroj√≥ mejores resultados.
![M√°triz](/images/matrix.png)
Se puede notar que en la mayor√≠a de las clases se obtuvo un mayor n√∫mero de predicciones correctas. Para cada clase se obtuvieron estos resultados:

### Angry:
Las predicciones correctas (angry ‚Üí angry) disminuyeron de 484 a 476.
Las confusiones con "fearful" disminuyeron de 53 a 37.
Las confusiones con "happy" aumentaron de 28 a 47.
Las confusiones con "neutral" disminuyeron de 128 a 111.
Las confusiones con "sad" aumentaron de 72 a 94.

### Fearful:
Las predicciones correctas (fearful ‚Üí fearful) disminuyeron de 380 a 279.
Las confusiones con "angry" aumentaron ligeramente de 112 a 124.
Las confusiones con "happy" aumentaron levemente de 33 a 35.
Las confusiones con "neutral" aumentaron de 109 a 128.
Las confusiones con "sad" aumentaron considerablemente de 147 a 215.

### Happy:
Las predicciones correctas (happy ‚Üí happy) aumentaron ligeramente de 1223 a 1227.
Las confusiones con las dem√°s emociones disminuyeron en general.

### Neutral:
Las predicciones correctas (neutral ‚Üí neutral) disminuyeron de 691 a 675.
Las confusiones con "angry" y "fearful" aumentaron levemente.
Las confusiones con "happy" aumentaron de 75 a 78.
Las confusiones con "sad" aumentaron de 88 a 107.

### Sad:
Las predicciones correctas (sad ‚Üí sad) aumentaron de 483 a 498.
Las confusiones con "angry" disminuyeron de 104 a 100.
Las confusiones con "fearful" disminuyeron de 82 a 49.
Las confusiones con "happy" aumentaron ligeramente de 44 a 50.
Las confusiones con "neutral" aumentaron de 214 a 230.

En resumen, el modelo mejor√≥ ligeramente en la predicci√≥n de "happy" y "sad", pero empeor√≥ en las dem√°s emociones, especialmente en "fearful" donde aumentaron significativamente las confusiones con "sad". En general, el modelo parece tener m√°s dificultad distinguiendo entre algunas emociones en la segunda matriz.

Estos resultados se ven reflejados en los resultados de recall, precision y f1-score.
![ClassificationReport](/images/cr.png)

Mejoras:

La precisi√≥n (precision) para "angry" mejor√≥ de 0.60 a 0.62.
El recall para "angry" mejor√≥ ligeramente de 0.62 a 0.63.
El recall para "fearful" mejor√≥ significativamente de 0.36 a 0.49.
La precisi√≥n para "happy" mejor√≥ de 0.85 a 0.87.
El recall para "happy" se mantuvo igual en 0.89.
El recall para "neutral" mejor√≥ de 0.72 a 0.74.
La precisi√≥n para "sad" mejor√≥ de 0.53 a 0.60.
La precisi√≥n (accuracy), el promedio macro (macro avg) y el promedio ponderado (weighted avg) mejoraron ligeramente.

Empeoramientos:

La precisi√≥n para "fearful" empeor√≥ de 0.68 a 0.65.
El f1-score para "fearful" empeor√≥ de 0.47 a 0.46.
El f1-score para "neutral" empeor√≥ ligeramente de 0.63 a 0.64.
El recall para "sad" empeor√≥ significativamente de 0.54 a 0.52.
El f1-score para "sad" empeor√≥ de 0.53 a 0.56.

Hubo mejoras en la mayor√≠a de las m√©tricas, especialmente en el recall de "fearful" y la precisi√≥n de "sad". Sin embargo, tambi√©n se observan algunos empeoramientos, sobre todo en el recall de "sad". En general, parece haber una mejora ligera en el desempe√±o global seg√∫n las m√©tricas de accuracy y los promedios.


Aunque el test accuracy aument√≥ y el test loss disminuy√≥ con respecto al modelo original, se puede notar que en estos resultados existe **overfitting** ya que la diferencia de loss entre test y train es de 16%. De acuerdo con la siguiente gr√°fica se puede decir que existe **overfitting**.

![Gr√°fica](/images/ref_graf.jpeg)

A√∫n as√≠ los resultados obtenidos se acercan m√°s a los del estado del arte. Se acerca all accuracy de 0.69 obtenido por Bodapati y Strilakshmi en el art√≠culo de investigaci√≥n "A Deep CNN Architecture for Facial Expression Recognition in the Wild." Adem√°s, de acuerdo con Amil Khanzada, Charles Bai y Ferhat Turker Celepcikay en el art√≠culo "Facial Expression Recognition with Deep Learning" debido al ruido del dataset solo es posible superar el 0.70 de accuracy utilizando t√©cnicas de registro de puntos faciales antes de realizar la clasificaci√≥n de im√°genes o bien utilizar modelos de transfer learning pre entrenados como ResNet50, VGG16 y SeNet50 que requieren una mayor capacidad de c√≥mputo qu ela disponible.

Cabe mencionar que el modelo tuvo un buen comportamiento con im√°genes de internet. Los resultados obtenidos con queries se encuentran en Testing.ipynb y fueron los siguientes.

![Queries](/images/queries.png)

![Queries](/images/queries2.png)



# Referencias
1. P. Verma, V. Aggrawal, and J. Maggu, "FExR.A-DCNN: Facial Emotion Recognition with Attention Mechanism using Deep Convolution Neural Network," in *Proc. 2022 Fourteenth Int. Conf. Contemporary Computing (IC3-2022)*, New York, NY, USA, 2022, pp. 196‚Äì203. doi: 10.1145/3549206.3549243.
2. Bodapati, J.D., Srilakshmi, U. & Veeranjaneyulu, N. FERNet: A Deep CNN Architecture for Facial Expression Recognition in the Wild. J. Inst. Eng. India Ser. B 103, 439‚Äì448 (2022). https://doi.org/10.1007/s40031-021-00681-8
3. A. Ananthu, "Emotion Detection FER Dataset," Kaggle, 2023. [Online]. Available: https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer?select=train. [Accessed: 19-May-2024].
4. S. P. Shuvo, "split_folders for train test val split of images," Kaggle, 2023. [Online]. Available: https://www.kaggle.com/code/shuvostp/split-folders-for-train-test-val-split-of-images. [Accessed: 19-May-2024].
5. Khanzada, A., Bai, C., Celepcikay, F. T., & Khosla, A. (2018). Facial expression recognition with deep learning. Stanford University. https://cs231n.stanford.edu/reports/2016/pdfs/023_Report.pdf 
6. "CK+ dataset" Kaggle, 2023. [Online]. Available: https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer?select=train. [Accessed: 4-June-2024].


